{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .venv (Python 3.10.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insightface.app import FaceAnalysis\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d004285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Manish images + embedding.\n"
     ]
    }
   ],
   "source": [
    "import shutil, pickle, os\n",
    "\n",
    "EMB_PATH = \"embeddings_arcface.pkl\"\n",
    "user_name = \"Manish\"  # delete this user\n",
    "\n",
    "# delete images\n",
    "folder_path = f\"enrolled_images/{user_name}\"\n",
    "shutil.rmtree(folder_path, ignore_errors=True)\n",
    "\n",
    "# delete from DB\n",
    "if os.path.exists(EMB_PATH):\n",
    "    with open(EMB_PATH, 'rb') as f:\n",
    "        db = pickle.load(f)\n",
    "    if user_name in db:\n",
    "        del db[user_name]\n",
    "        with open(EMB_PATH, 'wb') as f:\n",
    "            pickle.dump(db, f)\n",
    "        print(f\"Deleted {user_name} images + embedding.\")\n",
    "    else:\n",
    "        print(\"User not found in DB.\")\n",
    "else:\n",
    "    print(\"DB file not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd541a3f",
   "metadata": {},
   "source": [
    "TESTING -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "826be1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Loaded embeddings DB: ['', 'Neeraja', 'neeraja', 'Ronit', 'Manish', 'Arti', 'manish', 'arti']\n",
      "Starting enrollment for arti\n",
      "Enrollment complete for arti, images saved at enrolled_images/arti\n",
      "Enrollment finished for all users.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "import time\n",
    "\n",
    "# ----------------- Config -----------------\n",
    "EMB_PATH = \"embeddings_arcface.pkl\"\n",
    "\n",
    "# ----------------- Initialize ArcFace -----------------\n",
    "device = 0  # 0 = GPU, -1 = CPU\n",
    "arcface_app = FaceAnalysis(\n",
    "    name='buffalo_l',\n",
    "    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    ")\n",
    "arcface_app.prepare(ctx_id=device, det_size=(640, 640))\n",
    "\n",
    "# ----------------- Load or Create DB -----------------\n",
    "if os.path.exists(EMB_PATH):\n",
    "    with open(EMB_PATH, 'rb') as f:\n",
    "        embeddings_db = pickle.load(f)\n",
    "    print(\"Loaded embeddings DB:\", list(embeddings_db.keys()))\n",
    "else:\n",
    "    embeddings_db = {}\n",
    "    print(\"Starting with empty DB\")\n",
    "\n",
    "# ----------------- Liveliness (Blink) Check -----------------\n",
    "def is_blink_detected(face_landmarks, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Very simple blink check using eye position difference.\n",
    "    InsightFace returns 5 landmarks:\n",
    "    0: left eye, 1: right eye, 2: nose tip, 3: left mouth, 4: right mouth\n",
    "    \"\"\"\n",
    "    if face_landmarks is None or len(face_landmarks) < 5:\n",
    "        return False\n",
    "    left_eye = face_landmarks[0]\n",
    "    right_eye = face_landmarks[1]\n",
    "    # Use y-difference between eyes as a proxy\n",
    "    eye_dist = abs(left_eye[1] - right_eye[1])\n",
    "    return eye_dist < threshold  # crude check\n",
    "\n",
    "# ----------------- Enrollment -----------------\n",
    "def enroll_user_from_camera(name, num_images=50, wait_between=0.3):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    captured = 0\n",
    "    embeds = []\n",
    "\n",
    "    save_folder = f\"enrolled_images/{name}\"\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    print(f\"Starting enrollment for {name}\")\n",
    "\n",
    "    while captured < num_images:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        faces = arcface_app.get(frame)\n",
    "        if faces:\n",
    "            face = faces[0]\n",
    "            emb = face.embedding\n",
    "\n",
    "            # crude blink/liveliness check\n",
    "            if face.kps is not None:\n",
    "                blink = is_blink_detected(face.kps)\n",
    "                if blink:\n",
    "                    print(\"Blink detected ✅\")\n",
    "\n",
    "            embeds.append(emb)\n",
    "\n",
    "            # clamp bbox and save cropped face image safely\n",
    "            x1, y1, x2, y2 = face.bbox.astype(int)\n",
    "            h, w = frame.shape[:2]\n",
    "            x1 = max(0, x1); y1 = max(0, y1)\n",
    "            x2 = min(w, x2); y2 = min(h, y2)\n",
    "\n",
    "            if x2 > x1 and y2 > y1:\n",
    "                face_img = frame[y1:y2, x1:x2]\n",
    "                if face_img.size != 0:\n",
    "                    cv2.imwrite(f\"{save_folder}/{captured+1}.jpg\", face_img)\n",
    "\n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{captured+1}/{num_images}\", (x1, y1-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "            captured += 1\n",
    "            time.sleep(wait_between)\n",
    "\n",
    "        cv2.imshow(\"Enrollment\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if embeds:\n",
    "        mean_emb = np.mean(np.array(embeds), axis=0)\n",
    "        mean_emb /= np.linalg.norm(mean_emb)\n",
    "        embeddings_db[name] = mean_emb\n",
    "        with open(EMB_PATH, 'wb') as f:\n",
    "            pickle.dump(embeddings_db, f)\n",
    "        print(f\"Enrollment complete for {name}, images saved at {save_folder}\")\n",
    "    else:\n",
    "        print(\"Enrollment failed\")\n",
    "\n",
    "# ----------------- Main Loop -----------------\n",
    "while True:\n",
    "    person_name = input(\"Enter the name of the person to enroll: \")\n",
    "    enroll_user_from_camera(person_name, num_images=200, wait_between=0.3)\n",
    "    more = input(\"Do you want to enroll another person? (y/n): \")\n",
    "    if more.lower() != 'y':\n",
    "        print(\"Enrollment finished for all users.\")\n",
    "        break  # <— only break, removed the comment text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abccbc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (320, 320)\n",
      "✅ Using GPU: NVIDIA GeForce RTX 2050, Total Memory: 4096.0 MB\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import mediapipe as mp\n",
    "from insightface.app import FaceAnalysis\n",
    "import pickle\n",
    "import psutil\n",
    "import GPUtil\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "EMB_PATH = \"embeddings_arcface.pkl\"\n",
    "RECOG_THRESHOLD = 0.55\n",
    "EAR_CONSEC_FRAMES = 2\n",
    "BLINK_WINDOW_SECONDS = 5\n",
    "MOVEMENT_THRESHOLD = 2.0\n",
    "PROCESS_FACE_MESH_EVERY = 5  # run face mesh for liveness every 5 frames\n",
    "\n",
    "# ---------------- GPU Setup ----------------\n",
    "device = 0  # GPU\n",
    "arcface_app = FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider'])\n",
    "arcface_app.prepare(ctx_id=device, det_size=(320,320))\n",
    "\n",
    "# ---------------- Face Mesh Setup ----------------\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=3,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "\n",
    "def eye_aspect_ratio(landmarks, eye_indices, w, h):\n",
    "    coords = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in eye_indices]\n",
    "    A = np.linalg.norm(np.array(coords[1])-np.array(coords[5]))\n",
    "    B = np.linalg.norm(np.array(coords[2])-np.array(coords[4]))\n",
    "    C = np.linalg.norm(np.array(coords[0])-np.array(coords[3]))\n",
    "    return (A+B)/(2.0*C)\n",
    "\n",
    "# ---------------- Load embeddings ----------------\n",
    "with open(EMB_PATH, \"rb\") as f:\n",
    "    embeddings_db = pickle.load(f)\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    return np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def identify_face(emb):\n",
    "    emb = emb/np.linalg.norm(emb)\n",
    "    best_score,best_name = 0,\"Unknown\"\n",
    "    for name,ref_emb in embeddings_db.items():\n",
    "        ref_emb = ref_emb/np.linalg.norm(ref_emb)\n",
    "        score = cosine_similarity(emb,ref_emb)\n",
    "        if score > best_score:\n",
    "            best_score,best_name = score,name\n",
    "    if best_score < RECOG_THRESHOLD:\n",
    "        best_name = \"Unknown\"\n",
    "    return best_name,best_score\n",
    "\n",
    "# ---------------- Live Recognition ----------------\n",
    "def live_webcam_recognition():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    face_tracks = {}\n",
    "    prev_time = time.time()\n",
    "    frame_count = 0\n",
    "    gpu = GPUtil.getGPUs()[0]\n",
    "    print(f\"✅ Using GPU: {gpu.name}, Total Memory: {gpu.memoryTotal} MB\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        start_time = time.time()\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "        # Resize for speed\n",
    "        small_frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "        # ---------------- ArcFace ----------------\n",
    "        faces = arcface_app.get(small_frame)\n",
    "\n",
    "        # ---------------- Face Mesh every N frames ----------------\n",
    "        landmarks_all = []\n",
    "        if frame_count % PROCESS_FACE_MESH_EVERY == 0:\n",
    "            rgb = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(rgb)\n",
    "            landmarks_all = results.multi_face_landmarks if results.multi_face_landmarks else []\n",
    "\n",
    "        for idx, face in enumerate(faces):\n",
    "            # Scale bbox back to original size\n",
    "            x1,y1,x2,y2 = (face.bbox.astype(int) * 2)\n",
    "            emb = face.embedding\n",
    "            name,score = identify_face(emb)\n",
    "            color = (0,255,0) if name!=\"Unknown\" else (0,0,255)\n",
    "            face_id = f\"{name}_{idx}\"\n",
    "\n",
    "            if face_id not in face_tracks:\n",
    "                face_tracks[face_id] = {\n",
    "                    \"blink_times\": deque(),\n",
    "                    \"ear_counter\":0,\n",
    "                    \"ear_baseline\":0.26,\n",
    "                    \"last_pos\":((x1+x2)//2,(y1+y2)//2),\n",
    "                    \"movement\":0.0\n",
    "                }\n",
    "\n",
    "            is_live, ear_val = False,None\n",
    "            if landmarks_all:\n",
    "                best_mesh = min(landmarks_all, key=lambda lm: abs((lm.landmark[1].x*w/2)-(x1+x2)/4))\n",
    "                lm = best_mesh.landmark\n",
    "                leftEAR = eye_aspect_ratio(lm,LEFT_EYE,w/2,h/2)\n",
    "                rightEAR = eye_aspect_ratio(lm,RIGHT_EYE,w/2,h/2)\n",
    "                ear_val = (leftEAR+rightEAR)/2.0\n",
    "\n",
    "                base = face_tracks[face_id][\"ear_baseline\"]\n",
    "                ear_threshold = base*0.8\n",
    "\n",
    "                if ear_val<ear_threshold:\n",
    "                    face_tracks[face_id][\"ear_counter\"]+=1\n",
    "                else:\n",
    "                    if face_tracks[face_id][\"ear_counter\"]>=EAR_CONSEC_FRAMES:\n",
    "                        face_tracks[face_id][\"blink_times\"].append(time.time())\n",
    "                    face_tracks[face_id][\"ear_counter\"]=0\n",
    "                    face_tracks[face_id][\"ear_baseline\"]=0.9*base+0.1*ear_val\n",
    "\n",
    "                now = time.time()\n",
    "                while face_tracks[face_id][\"blink_times\"] and (now-face_tracks[face_id][\"blink_times\"][0])>BLINK_WINDOW_SECONDS:\n",
    "                    face_tracks[face_id][\"blink_times\"].popleft()\n",
    "\n",
    "                blink_count = len(face_tracks[face_id][\"blink_times\"])\n",
    "                is_live = blink_count>0\n",
    "\n",
    "                # Movement\n",
    "                cx,cy = (x1+x2)//2,(y1+y2)//2\n",
    "                lx,ly = face_tracks[face_id][\"last_pos\"]\n",
    "                move_dist = np.hypot(cx-lx, cy-ly)\n",
    "                face_tracks[face_id][\"movement\"]=0.8*face_tracks[face_id][\"movement\"]+0.2*move_dist\n",
    "                face_tracks[face_id][\"last_pos\"]=(cx,cy)\n",
    "                is_live = is_live or (face_tracks[face_id][\"movement\"]>MOVEMENT_THRESHOLD)\n",
    "\n",
    "            # Draw\n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),color,2)\n",
    "            cv2.putText(frame,f\"{name} ({score*100:.0f}%)\",(x1,y1-10),cv2.FONT_HERSHEY_SIMPLEX,0.7,color,2)\n",
    "            status_text=\"LIVE\" if is_live else \"NOT LIVE\"\n",
    "            status_color=(0,255,0) if is_live else (0,0,255)\n",
    "            cv2.putText(frame,f\"Liveness: {status_text}\",(x1,y2+25),cv2.FONT_HERSHEY_SIMPLEX,0.7,status_color,2)\n",
    "            if ear_val:\n",
    "                cv2.putText(frame,f\"EAR: {ear_val:.3f}\",(x1,y2+45),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,255,0),2)\n",
    "            cv2.putText(frame,f\"Movement: {face_tracks[face_id]['movement']:.1f}\",(x1,y2+65),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),1)\n",
    "\n",
    "        # FPS\n",
    "        curr_time = time.time()\n",
    "        fps = 1/(curr_time-prev_time)\n",
    "        prev_time = curr_time\n",
    "        inf_time = (time.time()-start_time)*1000\n",
    "        mem_usage = psutil.virtual_memory().percent\n",
    "        gpu_load = gpu.load*100\n",
    "        gpu_mem = gpu.memoryUsed\n",
    "\n",
    "        cv2.putText(frame,f\"FPS: {fps:.1f}\",(10,30),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255),2)\n",
    "        cv2.putText(frame,f\"Inference: {inf_time:.1f}ms\",(10,60),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255),2)\n",
    "        cv2.putText(frame,f\"Memory: {mem_usage:.1f}%\",(10,90),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255),2)\n",
    "        cv2.putText(frame,f\"GPU: {gpu_load:.1f}% | VRAM: {gpu_mem:.1f}MB\",(10,120),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255),2)\n",
    "\n",
    "        cv2.imshow(\"GPU Face Recognition + Liveness\",frame)\n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ---------------- Run ----------------\n",
    "live_webcam_recognition()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd58c2",
   "metadata": {},
   "source": [
    "COMPRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758a56db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "print(\"Available providers:\", ort.get_available_providers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91fa91c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\ganes/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "✅ FaceAnalysis ready on GPU!\n"
     ]
    }
   ],
   "source": [
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# 1️⃣ GPU first, CPU fallback\n",
    "arcface_app = FaceAnalysis(\n",
    "    name='buffalo_l',\n",
    "    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    ")\n",
    "\n",
    "# 2️⃣ ctx_id=0 = first GPU\n",
    "arcface_app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "# 3️⃣ आता model GPU वर चालेल\n",
    "print(\"✅ FaceAnalysis ready on GPU!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c7cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "print(ort.get_available_providers())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
